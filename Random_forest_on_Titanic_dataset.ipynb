{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random forest on Titanic dataset",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1Mc2x0Vvxd1nkq8V8XwjY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iabhi009/AI-Plays-Dont-Let-the-Freaking-Ball-touch-the-Ground/blob/master/Random_forest_on_Titanic_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F8MPW-8gH12",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest on Titanic Dataset\n",
        " Author: Abhishek Pathak"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km4Z9cPsf78i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic Utilities\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# For Label Encoding\n",
        "from sklearn import preprocessing \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "\n",
        "# For Printing Accuracy of our prediction\n",
        "from sklearn.metrics import accuracy_score\n",
        "# For Importing the Random Forest Classifier \n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVySYzahx3j",
        "colab_type": "text"
      },
      "source": [
        "Now We will import our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeEi6_dejn1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "survived = pd.read_csv(\"gender_submission.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtPV651mk8H4",
        "colab_type": "text"
      },
      "source": [
        "After importing the next Step is pre processing\n",
        "we will pre process in the following order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djcBkqGxj7Hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "f2ce15af-a2f7-4859-aae4-3e471fec9b8f"
      },
      "source": [
        "# Pre Processing\n",
        "\n",
        "#Checking for NULL values\n",
        "print(train.info())\n",
        "#print(test.info())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            "PassengerId    891 non-null int64\n",
            "Survived       891 non-null int64\n",
            "Pclass         891 non-null int64\n",
            "Name           891 non-null object\n",
            "Sex            891 non-null object\n",
            "Age            714 non-null float64\n",
            "SibSp          891 non-null int64\n",
            "Parch          891 non-null int64\n",
            "Ticket         891 non-null object\n",
            "Fare           891 non-null float64\n",
            "Cabin          204 non-null object\n",
            "Embarked       889 non-null object\n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovHOuBJpn37C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Age            714 non-null float64\n",
        "Cabin          204 non-null object\n",
        "Embarked       889 non-null object\n",
        "They have missing values\n",
        "\n",
        "'''\n",
        "# We replace the Null values with mean of the particualr column\n",
        "train = train.fillna(train.mean())\n",
        "test = test.fillna(test.mean())\n",
        "# basically, fill ages with mean of all ages\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJM4d2pKlLXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6e7b5e14-0cb1-4308-8fc0-f53208317e38"
      },
      "source": [
        "'''\n",
        "# Label Encoding\n",
        "\n",
        "source -> https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/\n",
        "As we know computer can only understand numbers and not strings.\n",
        "so sex like 'male' and 'female' would hard for the computer to decide\n",
        "\n",
        "hence we will change it into features \n",
        "the numbering depends upon which features comes first\n",
        "1- male\n",
        "0- female\n",
        "'''\n",
        "print(train['Sex'].unique()) \n",
        "train['Sex']= label_encoder.fit_transform(train['Sex']) \n",
        "print(train['Sex'].unique())\n",
        "test['Sex']= label_encoder.fit_transform(test['Sex']) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['male' 'female']\n",
            "[1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obZc99dOlQ8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7badf99c-cc12-4b91-a89c-a25889101786"
      },
      "source": [
        "'''\n",
        "Feature Selection\n",
        "\n",
        "Deciding what all features to be used in our datset.\n",
        "As we can see Name  , Ticket , Cabin , Embarked have string type\n",
        "\n",
        "'''\n",
        "print(\"Original features:\")\n",
        "print(train.columns)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original features:\n",
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioYk8XbYoOmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Lets removing features we don't want\n",
        "# Backward Selection\n",
        "\n",
        "let's remove all the colums that have string values\n",
        "or are not a feature \n",
        "'''\n",
        "#Name\n",
        "train.drop(columns=[\"Name\"],inplace= True)\n",
        "test.drop(columns=[\"Name\"],inplace=True)\n",
        "#Ticket\n",
        "train.drop(columns=[\"Ticket\"],inplace= True)\n",
        "test.drop(columns=[\"Ticket\"],inplace=True)\n",
        "#Cabin\n",
        "train.drop(columns=[\"Cabin\"],inplace= True)\n",
        "test.drop(columns=[\"Cabin\"],inplace=True)\n",
        "#Embarked\n",
        "train.drop(columns=[\"Embarked\"],inplace= True)\n",
        "test.drop(columns=[\"Embarked\"],inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1EM2CqMpxNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e48421f0-7668-4327-f693-5a057d1982f5"
      },
      "source": [
        "print(train.columns)\n",
        "print(test.columns)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
            "       'Fare'],\n",
            "      dtype='object')\n",
            "Index(['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMM7PDmWqTnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "57587bd2-fad0-485e-a67e-ad8271c2164a"
      },
      "source": [
        "'''\n",
        "Now Let's Split our Data base into\n",
        "train - all the featues of our traing dataset\n",
        "train_result - traing dataset result\n",
        "test - all the features of our testing dataset\n",
        "test_original - original result for testing accuracy\n",
        "test_prediction - our predicted result\n",
        "'''\n",
        "\n",
        "train_result = train[\"Survived\"]\n",
        "train.drop(columns=[\"Survived\"],inplace= True)\n",
        "print(\"Traing Features:\")\n",
        "print(train.columns)\n",
        "print(\"Testing Features:\")\n",
        "print(test.columns)\n",
        "test_original = survived[\"Survived\"].to_numpy()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traing Features:\n",
            "Index(['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')\n",
            "Testing Features:\n",
            "Index(['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8x-_Pt7xFvg",
        "colab_type": "text"
      },
      "source": [
        "Now our Actual Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI2sjFVerPcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "Creating a model using RandomForestClassifier library\n",
        "'''\n",
        "model = RandomForestClassifier(n_jobs=2, random_state=0)\n",
        "# Don't ask me what those parameters does....study theory for details\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxKUQZSbxrx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0c552e5b-b52f-4757-81f2-33740d428d94"
      },
      "source": [
        "# Traing our Model\n",
        "# To train our model we will give it the training features \n",
        "# with correct answers\n",
        "# More of like teaching a student by showing him images that the image is cat or dog\n",
        "model.fit(train, train_result)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
              "                       oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-JG-FxqxKK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting Predictions\n",
        "# take a suprise test by showing it new features which it was'nt trained upon\n",
        "# and asking our model what he thinks those features mean\n",
        "test_predict=model.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLYu57I9yAI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4768e826-556c-4c99-e8bd-f44aa06418a0"
      },
      "source": [
        "print(test_predict)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
            " 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
            " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
            " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 0 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-06rTi6AzBe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "266df193-3b66-4dc5-d74a-c2b598370d9d"
      },
      "source": [
        "# Comparing Accuracy\n",
        "print(\"Accuracy:\",accuracy_score(test_predict,test_original)*100)\n",
        "print(\"Error Rate\",100-(accuracy_score(test_predict,test_original)*100))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 78.4688995215311\n",
            "Error Rate 21.5311004784689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwJIOnWCzCz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c11d640d-5411-4e9e-91d3-3a6c5d16966d"
      },
      "source": [
        "# Comparing output side by side\n",
        "view = 10\n",
        "for x in range(view):\n",
        "    l=\"\"\n",
        "    if test_predict[x] != survived[\"Survived\"].iloc[x]:\n",
        "        l=\"False\"\n",
        "\n",
        "    print(survived[\"PassengerId\"].iloc[x],test_predict[x] ,survived[\"Survived\"].iloc[x],' - ',l)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "892 0 0  -  \n",
            "893 0 1  -  False\n",
            "894 0 0  -  \n",
            "895 0 0  -  \n",
            "896 0 1  -  False\n",
            "897 0 0  -  \n",
            "898 0 1  -  False\n",
            "899 0 0  -  \n",
            "900 1 1  -  \n",
            "901 0 0  -  \n",
            "902 0 0  -  \n",
            "903 0 0  -  \n",
            "904 1 1  -  \n",
            "905 0 0  -  \n",
            "906 1 1  -  \n",
            "907 1 1  -  \n",
            "908 0 0  -  \n",
            "909 0 0  -  \n",
            "910 0 1  -  False\n",
            "911 0 1  -  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbDWBMF9zlC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1b91a198-06af-4ae7-8702-55e8c64e5ec1"
      },
      "source": [
        " '''\n",
        " Now let's have fun around\n",
        " Go to backward selection part and drop fare ( cost of ticket)\n",
        " and re run the model . you'll find the accuracy to drop by 2-3%\n",
        "\n",
        " which means that the cost of the ticket also played a role in the survival of the people\n",
        "\n",
        " possible the richer people had better access to boat\n",
        "\n",
        " that's why approach of correlation should be taken into consideration at the start of \n",
        " any problem\n",
        "\n",
        "\n",
        " Go to https://www.kaggle.com/c/titanic/notebooks\n",
        " to find different peoples approach of the same problem with better accuracy\n",
        " '''\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nNow let's have fun around\\nGo to backward selection part and drop fare ( cost of ticket)\\nand re run the model . you'll find the accuracy to drop by 2-3%\\n\\nwhich means that the cost of the ticket also played a role in the survival of the people\\n\\npossible the richer people had better access to boat\\n\\nthat's why approach of correlation should be taken into consideration at the start of \\nany problem\\n\\n\\nGo to https://www.kaggle.com/c/titanic/notebooks\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtY_UX10c_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "4c4d4bc8-6105-464d-87be-0a30c7e5799b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeRLJvNyzo7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}